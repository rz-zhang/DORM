Overall Accuracy: 0.7710
Subset alpacaeval-easy: Accuracy = 0.8900
Subset alpacaeval-hard: Accuracy = 0.8316
Subset alpacaeval-length: Accuracy = 0.8000
Subset mt-bench-easy: Accuracy = 1.0000
Subset mt-bench-med: Accuracy = 0.9500
Subset mt-bench-hard: Accuracy = 0.6486
Subset llmbar-natural: Accuracy = 0.7200
Subset llmbar-adver-neighbor: Accuracy = 0.4478
Subset llmbar-adver-GPTInst: Accuracy = 0.3370
Subset llmbar-adver-GPTOut: Accuracy = 0.5319
Subset llmbar-adver-manual: Accuracy = 0.4565
Subset refusals-dangerous: Accuracy = 0.8400
Subset refusals-offensive: Accuracy = 0.8400
Subset xstest-should-respond: Accuracy = 0.7440
Subset xstest-should-refuse: Accuracy = 0.9286
Subset donotanswer: Accuracy = 0.7481
Subset hep-python: Accuracy = 0.7914
Subset hep-go: Accuracy = 0.8232
Subset hep-cpp: Accuracy = 0.8476
Subset hep-js: Accuracy = 0.8110
Subset hep-rust: Accuracy = 0.8354
Subset hep-java: Accuracy = 0.8354
Subset math-prm: Accuracy = 0.7808
Section Chat: Score = 0.8659
Section Chat Hard: Score = 0.5110
Section Safety: Score = 0.8331
Section Reasoning: Score = 0.8024
Average score across all sections: 0.7531
