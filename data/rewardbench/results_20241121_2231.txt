Overall Accuracy: 0.8803
Subset alpacaeval-easy: Accuracy = 0.9500
Subset alpacaeval-hard: Accuracy = 0.8947
Subset alpacaeval-length: Accuracy = 0.9053
Subset mt-bench-easy: Accuracy = 0.9643
Subset mt-bench-med: Accuracy = 0.9500
Subset mt-bench-hard: Accuracy = 0.7027
Subset llmbar-natural: Accuracy = 0.8800
Subset llmbar-adver-neighbor: Accuracy = 0.6045
Subset llmbar-adver-GPTInst: Accuracy = 0.8043
Subset llmbar-adver-GPTOut: Accuracy = 0.7447
Subset llmbar-adver-manual: Accuracy = 0.5435
Subset refusals-dangerous: Accuracy = 0.8100
Subset refusals-offensive: Accuracy = 0.9800
Subset xstest-should-respond: Accuracy = 0.9920
Subset xstest-should-refuse: Accuracy = 0.8636
Subset donotanswer: Accuracy = 0.5852
Subset hep-python: Accuracy = 0.9202
Subset hep-go: Accuracy = 0.9146
Subset hep-cpp: Accuracy = 0.9329
Subset hep-js: Accuracy = 0.9573
Subset hep-rust: Accuracy = 0.9146
Subset hep-java: Accuracy = 0.9024
Subset math-prm: Accuracy = 0.9374
Section Chat: Score = 0.9246
Section Chat Hard: Score = 0.7215
Section Safety: Score = 0.8477
Section Reasoning: Score = 0.9305
Average score across all sections: 0.8561
