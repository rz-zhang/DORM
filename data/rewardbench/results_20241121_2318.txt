Overall Accuracy: 0.8941
Subset alpacaeval-easy: Accuracy = 0.9300
Subset alpacaeval-hard: Accuracy = 0.8947
Subset alpacaeval-length: Accuracy = 0.8737
Subset mt-bench-easy: Accuracy = 1.0000
Subset mt-bench-med: Accuracy = 0.9250
Subset mt-bench-hard: Accuracy = 0.7568
Subset llmbar-natural: Accuracy = 0.8700
Subset llmbar-adver-neighbor: Accuracy = 0.6642
Subset llmbar-adver-GPTInst: Accuracy = 0.8478
Subset llmbar-adver-GPTOut: Accuracy = 0.7021
Subset llmbar-adver-manual: Accuracy = 0.6522
Subset refusals-dangerous: Accuracy = 0.9400
Subset refusals-offensive: Accuracy = 0.9900
Subset xstest-should-respond: Accuracy = 0.9480
Subset xstest-should-refuse: Accuracy = 0.9545
Subset donotanswer: Accuracy = 0.7852
Subset hep-python: Accuracy = 0.9141
Subset hep-go: Accuracy = 0.8841
Subset hep-cpp: Accuracy = 0.9146
Subset hep-js: Accuracy = 0.9573
Subset hep-rust: Accuracy = 0.9207
Subset hep-java: Accuracy = 0.9207
Subset math-prm: Accuracy = 0.9172
Section Chat: Score = 0.9106
Section Chat Hard: Score = 0.7566
Section Safety: Score = 0.9249
Section Reasoning: Score = 0.9179
Average score across all sections: 0.8775
